{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Building ETL Pipelines",
   "id": "3051fe8d958196d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate sample sales data\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'order_id': range(1, n_records + 1),\n",
    "    'customer_id': np.random.randint(1000, 2000, n_records),\n",
    "    'product_id': np.random.randint(100, 200, n_records),\n",
    "    'product_name': np.random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'], n_records),\n",
    "    'quantity': np.random.randint(1, 10, n_records),\n",
    "    'price': np.round(np.random.uniform(10, 1000, n_records), 2),\n",
    "    'order_date': [datetime(2024, 1, 1) + timedelta(days=int(x)) for x in np.random.randint(0, 365, n_records)],\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records),\n",
    "    'status': np.random.choice(['Completed', 'Pending', 'Cancelled'], n_records)\n",
    "})\n",
    "\n",
    "# Calculate total amount\n",
    "sample_data['total_amount'] = sample_data['quantity'] * sample_data['price']\n",
    "\n",
    "# Save to parquet file\n",
    "sample_data.to_parquet(\"../data/sales_data.parquet\", engine=\"fastparquet\", index=False)\n",
    "\n",
    "print(\"Sample sales_data.parquet created successfully!\")"
   ],
   "id": "59d0e36d972de93e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:00:55.516934Z",
     "start_time": "2025-10-28T14:00:55.504127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the sales data into a DataFrame\n",
    "sales_data = pd.read_parquet(\"../data/sales_data.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "# Check the data type of the columns of the DataFrames\n",
    "print(sales_data.dtypes)\n",
    "\n",
    "# Print the shape of the DataFrame, as well as the head\n",
    "print(sales_data.shape)\n",
    "print(sales_data.head())\n"
   ],
   "id": "178c418964f02083",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                 int64\n",
      "customer_id              int64\n",
      "product_id               int64\n",
      "product_name            object\n",
      "quantity                 int64\n",
      "price                  float64\n",
      "order_date      datetime64[ns]\n",
      "region                  object\n",
      "status                  object\n",
      "total_amount           float64\n",
      "dtype: object\n",
      "(1000, 10)\n",
      "   order_id  customer_id  product_id product_name  quantity   price  \\\n",
      "0         1         1102         104       Laptop         3  773.91   \n",
      "1         2         1435         132   Headphones         4  503.91   \n",
      "2         3         1860         164     Keyboard         7   21.98   \n",
      "3         4         1270         117   Headphones         1   18.95   \n",
      "4         5         1106         195       Laptop         7  363.46   \n",
      "\n",
      "  order_date region     status  total_amount  \n",
      "0 2024-07-09  South    Pending       2321.73  \n",
      "1 2024-06-30  North    Pending       2015.64  \n",
      "2 2024-11-30   West  Completed        153.86  \n",
      "3 2024-07-27  South  Cancelled         18.95  \n",
      "4 2024-01-22   West  Cancelled       2544.22  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pulling data from SQL databases\n",
    "SQL databases are one of the most used data storage tools in the world. Many companies have teams of several individuals responsible for creating and maintaining these databases, which typically store data crucial for day-to-day operations. These SQL databases are commonly used as source systems for a wide range of data pipelines."
   ],
   "id": "e030bc919bb93d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Create a connection to the sales database\n",
    "db_engine = sqlalchemy.create_engine(\"postgresql+psycopg2://repl:password@localhost:5432/sales\")\n",
    "\n",
    "# Query the sales table\n",
    "raw_sales_data = pd.read_sql(\"SELECT * FROM sales;\", con=db_engine)\n",
    "print(raw_sales_data)\n"
   ],
   "id": "426f94dfc5ea62d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building functions to extract data\n",
    "It's important to modularize code when building a data pipeline. This helps to make pipelines more readable and reusable, and can help to expedite troubleshooting efforts. Creating and using functions for distinct operations in a pipeline can even help when getting started on a new project by providing a framework to begin development.\n",
    "\n",
    "pandas has been imported as pd, and sqlalchemy is ready to be used."
   ],
   "id": "c335644ed2daec8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract():\n",
    "    connection_uri = \"postgresql+psycopg2://repl:password@localhost:5432/sales\"\n",
    "    db_engine = sqlalchemy.create_engine(connection_uri)\n",
    "    raw_data = pd.read_sql(\"SELECT * FROM sales WHERE quantity_ordered = 1\", db_engine)\n",
    "\n",
    "    # Print the head of the DataFrame\n",
    "    print(raw_data.head())\n",
    "\n",
    "    # Return the extracted DataFrame\n",
    "    return raw_data\n",
    "\n",
    "# Call the extract() function\n",
    "raw_sales_data = extract()\n"
   ],
   "id": "70bc98140126e6cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a82fc123745bd180"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
